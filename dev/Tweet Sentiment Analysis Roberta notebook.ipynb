{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGvhXoncTeuM"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Azie88/NLP-Huggingface-Covid-19-Tweet-Sentiment-Analysis/blob/main/dev/Tweet%20Sentiment%20Analysis%20Roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgP-2i3dlJPv"
   },
   "source": [
    "# Sentiment Analysis with HuggingFace & Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IA9qoXrNLI2p"
   },
   "source": [
    "Deep learning has pretty much taken over NLP. Language models like those available through huggingface are able to capture nuances of text, and can be trained with very little effort. They are super easy to use.\n",
    "\n",
    "Hugging Face is an open-source and platform provider of machine learning technologies. You can use install their package to access some interesting pre-built models to use them directly or to fine-tune (retrain it on your dataset leveraging the prior knowledge coming with the first training), then host your trained models on the platform, so that you may use them later on other devices and apps. It's really awesome.\n",
    "\n",
    "\n",
    "The Hugging face models are Deep Learning based, so will need a lot of computational GPU power to train them. This project will use [Google Colab](https://colab.research.google.com/) to leverage the GPU computational power.\n",
    "\n",
    "This project is about Natural Language Processing, specifically text classification (Sentiment analysis). In this project, we will fine-tune a pre-trained text classification Deep Learning model from HuggingFace on a new dataset to adapt the models to the task that we want to solve, i.e the prediction of the sentiment expressed in a Tweet (e.g: neutral, positive, negative), then create an app to use the models and deploy the app on the HuggingFace platform.\n",
    "\n",
    "<br>\n",
    "\n",
    "Read more about [Text classification with Hugging Face](https://huggingface.co/tasks/text-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXDQK6a8NKgB"
   },
   "source": [
    "## Business Understanding\n",
    "\n",
    "Vaccines have lowered the risk of illness and death, and have saved countless lives around the world. Unfortunately in some countries, the 'anti-vaxxer' movement has led to lower rates of vaccination and new outbreaks of old diseases.\n",
    "\n",
    "The COVID vaccination has been very controversial and people have mixed feelings and opinions about it. Therefore, it is important to monitor public sentiment towards vaccinations now and in the future as the COVID-19 vaccines continue to be offered to the public. The anti-vaccination sentiment could pose a serious threat to the global efforts to get COVID-19 under control in the long term.\n",
    "\n",
    "The objective of this challenge is to develop a machine learning model to assess if a Twitter post related to COVID vaccinations is positive, neutral, or negative. This solution could help governments and other public health actors monitor public sentiment towards COVID-19 vaccinations and help improve public health policy, vaccine communication strategies, and vaccination programs across the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdY5zkow6Rbd"
   },
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zwiTSIUz7sK"
   },
   "source": [
    "### Install Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oLpN2fNMiaH",
    "outputId": "67150290-6596-442b-ded3-d646a58c9681"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install accelerate>=0.20.1\n",
    "!pip install transformers[torch]\n",
    "!pip install -U huggingface_hub\n",
    "!pip install tokenizers --upgrade\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGYBlFUE0JSR"
   },
   "source": [
    "### Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Fs6-m8zOs50"
   },
   "outputs": [],
   "source": [
    "#System and data handling\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import numpy as np\n",
    "\n",
    "#Data Preparation\n",
    "from evaluate import load\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "#Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Google Drive\n",
    "from google.colab import drive\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, TFAutoModelForSequenceClassification\n",
    "\n",
    "#Scores\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#Huggingface\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5CVL70P1NPQ"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "1a21d22e9f91425d955a1a506ca5110d",
      "88cbc25e7c5c4b78af27470f27fadeb9",
      "d5b50bb3aaa343ab8629587c47807a4a",
      "eb167345d37a40c5bb28e15b62f84099",
      "39028c5cc71645cb9b3e0faeed5ab26f",
      "e0b0ddd5fbd1439da5b892718cbf969b",
      "a54491b0ce5b47cbafd0abdd376ed7d1",
      "586e53d62d364af69fc926ff9fe0ed0d",
      "9483ea10a1f3408696a512b54875dd9d",
      "d6ef1e4dac364b4fbc5f689a8585a184",
      "0a97f4391f9f4fe2ba643e9cda58f52f",
      "4b08cb4521d34deeb67962c7e61dbfa6",
      "2cadf16252e84f25a89b813fd1576cb2",
      "e2e9f6b548e34dd0902290834f46167d",
      "7b2b65c8547e484e9ab382c85f345490",
      "e85777ef64a54d61a4ea808f49f75b73",
      "9ba4468c6b8a4d0fb0782425561b5c99",
      "a64da1923dfa49dea845ca89eac8b17e",
      "6a3082bc6edf4eeea0a42f04e5875191",
      "98cf3ad7ee7c43b1b240a5ff8da88505"
     ]
    },
    "id": "JX-rBXlT2hTf",
    "outputId": "eb47fd13-9646-4997-8dd4-4ae4c38907e4"
   },
   "outputs": [],
   "source": [
    "#login to huggingface with access token\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxgXe7lBXUyz"
   },
   "outputs": [],
   "source": [
    "# Set a fixed random seed for PyTorch on CPU\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Control the seed for individual GPU operations (optional)\n",
    "if torch.cuda.is_available:\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.cuda.manual_seed_all(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iw141gDSl_Hc",
    "outputId": "ca5f2de8-d05f-49db-fc30-bfa5b0ae5b4f"
   },
   "outputs": [],
   "source": [
    "# Connect to your google drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKMNMkFalJP6"
   },
   "outputs": [],
   "source": [
    "# Disabe W&B\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM9FHZdw2jSq"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BhJC4kWlJP6"
   },
   "outputs": [],
   "source": [
    "# Load the dataset and display some values\n",
    "df = pd.read_csv('/content/drive/MyDrive/Covid-19 tweet dataset/Train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "BDb0DiTTnha0",
    "outputId": "77563f0e-e050-4fcf-e365-e66156ea085d"
   },
   "outputs": [],
   "source": [
    "#look at first 10 rows in train data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwkvlyXY3vDk"
   },
   "source": [
    "1. **tweet_id**: Unique identifier of the tweet\n",
    "\n",
    "2. **safe_tweet**: Text contained in the tweet. Some sensitive information has been removed like usernames and urls\n",
    "\n",
    "3. **label**: Sentiment of the tweet (-1 for negative, 0 for neutral, 1 for positive)\n",
    "\n",
    "4. **agreement**: The tweets were labeled by three people. Agreement indicates the percentage of the three reviewers that agreed on the given label. You may use this column in your training, but agreement data will not be shared for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZR7503k4dX3",
    "outputId": "55410036-d106-4cbd-859a-928862302af5"
   },
   "outputs": [],
   "source": [
    "#Check rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "7JG0Xtz74fpQ",
    "outputId": "495fa741-22e4-4fba-9753-d824132db461"
   },
   "outputs": [],
   "source": [
    "#Check Data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "6BBRHpUDnofL",
    "outputId": "542e607f-9ee2-42e5-e2b7-e8c2e5fbac4f"
   },
   "outputs": [],
   "source": [
    "#Descriptive Statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "MDSoxO_I7SHJ",
    "outputId": "e7e45b2c-df15-41d0-82b7-fe4f66ef0cb0"
   },
   "outputs": [],
   "source": [
    "#Check Null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "uT-jlPZj7s0j",
    "outputId": "52e06ab8-b85c-441f-8f9f-13a5f4cb4d5a"
   },
   "outputs": [],
   "source": [
    "# Check the 'label' value counts\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "kLtzuXvn8Mtw",
    "outputId": "65ab5e5f-e8ab-4e24-caec-ff7644904cfc"
   },
   "outputs": [],
   "source": [
    "# Check for quality of 'safe_text' tweets\n",
    "df.safe_text.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAapsdOj_LqS"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "1. Remove rows with NaN values.\n",
    "2. Clean *safe-text* column of Twitter Handles, HTML characters, URLs and other non alphabetic characters. Text is inconsistent and may affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycOioYbs2Z92"
   },
   "outputs": [],
   "source": [
    "# Eliminate rows containing NaN values\n",
    "df = df[~df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "D7-ecrEqnyKj",
    "outputId": "f56c7311-fb94-49e6-b4c6-7c94198d8bc9"
   },
   "outputs": [],
   "source": [
    "# Check null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_zb8wlrAjOh"
   },
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "# Replace unwanted characters with empty string\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove tweet mentions\n",
    "    text = re.sub(r'<user>', '', text)\n",
    "    text = re.sub(r'<url>', '', text)\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Replace all whitespace characters with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NcY5yOE2Fg_a"
   },
   "outputs": [],
   "source": [
    "# Apply the clean_text function to the 'safe_text' column\n",
    "df['safe_text'] = df.safe_text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "9k5PjggxFp65",
    "outputId": "857a205a-9c81-428b-867e-89fdbf5de47b"
   },
   "outputs": [],
   "source": [
    "df.safe_text.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "NyjjPut6oFsK",
    "outputId": "f92f4ac3-1f38-4152-8aaf-27bf584cfa47"
   },
   "outputs": [],
   "source": [
    "# Check label value counts after deleting NaN values\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hriDHAb1GcsL"
   },
   "source": [
    "The target classes are imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMqosLcmCXCk"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "IqSESMjBoMlo",
    "outputId": "c5013e6a-8711-4ee8-f0ae-da9c842f2770"
   },
   "outputs": [],
   "source": [
    "# pie chart wth 'labels' column\n",
    "plt.figure(figsize=(6,6))\n",
    "explode=0.1,0\n",
    "df.label.value_counts().plot.pie(autopct='%1.2f%%',labels=['Neutral','Positive','Negative'])\n",
    "plt.legend(bbox_to_anchor=(1.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xn_m4kd9QmNg"
   },
   "source": [
    "Neutral and positive sentiments are more prevalent, while negative sentiments are relatively less frequent in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "kK4iKwj-pRgY",
    "outputId": "18a22df8-e7dd-4a45-935b-9a5b891b4345"
   },
   "outputs": [],
   "source": [
    "#generate a word cloud visualization from the 'safe_text' column\n",
    "\n",
    "all_data = df['safe_text'].to_string()\n",
    "wordcloud = WordCloud().generate(all_data)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.title('Word Cloud for Most Common Words')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4iNFUy6Jbuk"
   },
   "source": [
    "The word cloud provides a visual representation of the most frequent terms in the tweets. The size of each word in the cloud is proportional to its frequency. Lets look at how many words are in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zuFA81t5LbZv",
    "outputId": "9b30da82-eeaf-4ce2-ad3d-2218df0ee7c7"
   },
   "outputs": [],
   "source": [
    "# Number of words in each tweet in the 'safe_text' column\n",
    "text_lengths = df['safe_text'].str.split().str.len()\n",
    "text_lengths.value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziAnLj73QXN4"
   },
   "outputs": [],
   "source": [
    "# Calculate the average\n",
    "average_length = np.mean(text_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "w2uiT-OYNdjO",
    "outputId": "69249feb-4e4f-42da-9c3e-33be9842ebc5"
   },
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Using plt.hist to create a histogram with Matplotlib\n",
    "ax.hist(text_lengths, bins=20, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "\n",
    "# Add average line\n",
    "ax.axvline(average_length, color='red', linestyle='dashed', linewidth=2, label=f'Average: {average_length:.2f}')\n",
    "\n",
    "ax.set_title('Histogram of Tweet Lengths')\n",
    "ax.set_xlabel('Tweet Length')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc-5xBITKsWP"
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvVzzz8clJP7"
   },
   "outputs": [],
   "source": [
    "# Split the train data => {train, eval}\n",
    "train, eval = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c1BOta_rlJP7",
    "outputId": "a2b6f49e-3644-4adc-b96d-84773b1f865c"
   },
   "outputs": [],
   "source": [
    "#preview the train subset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "btLWG-8QlJP7",
    "outputId": "4a3cc5b6-4df2-4c2a-9da4-cdc04180e6d9"
   },
   "outputs": [],
   "source": [
    "#preview the eval subset\n",
    "eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_LfooKRlJP8",
    "outputId": "d7afa764-cc5c-41cf-c4a5-2bf5092ea033"
   },
   "outputs": [],
   "source": [
    "print(f\"new dataframe shapes: train is {train.shape}, eval is {eval.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hI1XT6BBlJP8"
   },
   "outputs": [],
   "source": [
    "# Save split subsets\n",
    "train.to_csv(\"/content/drive/MyDrive/Covid-19 tweet dataset/train_subset.csv\", index=False)\n",
    "eval.to_csv(\"/content/drive/MyDrive/Covid-19 tweet dataset/eval_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsxT1S8ea81k"
   },
   "source": [
    "## Model Fine Tuning and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZXF_NXz3t61"
   },
   "outputs": [],
   "source": [
    "# Define pre-trained model name and instance of tokenizer from the model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ_rM5K0bl_e"
   },
   "source": [
    "**Model**: Twitter-roBERTa-base for Sentiment Analysis - UPDATED (2022) [Model link on huggingface](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)\n",
    "\n",
    "**Description**: This is a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark.\n",
    "\n",
    "**Labels**:\n",
    "*   Negative --> 0\n",
    "*   Neutral --> 1\n",
    "*   Positive --> 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0IcKaDe36dz"
   },
   "outputs": [],
   "source": [
    "# Function to transform the labels:\n",
    "# Negative -1:0\n",
    "# Neutral 0:1\n",
    "# Positive 1:2\n",
    "\n",
    "def transform_labels(label):\n",
    "\n",
    "    label = label['label']\n",
    "    num = 0\n",
    "    if label == -1: #'Negative'\n",
    "        num = 0\n",
    "    elif label == 0: #'Neutral'\n",
    "        num = 1\n",
    "    elif label == 1: #'Positive'\n",
    "        num = 2\n",
    "\n",
    "    return {'labels': num}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKX5I0h75453"
   },
   "outputs": [],
   "source": [
    "# Convert dataframes to datasets objects\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "eval_dataset = Dataset.from_pandas(eval)\n",
    "\n",
    "# Create a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'eval': eval_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvT5QmARc62-"
   },
   "outputs": [],
   "source": [
    "# Function to tokenize data\n",
    "\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(example['safe_text'], max_length = 128, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "44c6f903b8be453c9969e6534ea2725a",
      "8e8ba2bf24a245b98efd06ddd255ed0e",
      "89bdb6e6fb784865aaec7e34903f4b0c",
      "8e1f1386a809464d9d86f4ce46a5bb3e",
      "56b5f173aee8483b9c618d8cb00a7e90",
      "d7deb020202545ccbcd3463c6f0b7fe6",
      "16080d4e74754de1a6ed3c2cb7e4a56e",
      "2f69d935c0c643c0ae8f7a0fffdcaea0",
      "f245092373d44137851d8e8deb368d02",
      "353628a1140c4784a1f8d9df14ef1e06",
      "80c2ec2ad1c841dab4ec7676dd0990f6",
      "cdc15ff494a5423bbaea89417b1bf7d3",
      "942022892f8f4495ac6277efcfd65ee7",
      "67b24d611f0b47bdb620bd5be7f5ef8a",
      "cafbdcb8935d4d5d88c7e97371056fc1",
      "abe0d6caabeb4cb392f479a170de40de",
      "a665138303534f76b3d92b1f6bad8b1b",
      "b855bea2a7be4fa0a6c0d829e067a1e0",
      "333567c7adc84d67a7b90362874f7630",
      "07937c65929844cb989295abc7011c7f",
      "fdb8097e2aaa4449bfccb0923d78916b",
      "9f40324d25e94959b82fd0af7ab55946",
      "f6fc532c04a14afcb7b835f65065b858",
      "64b8f560ce144df182f6d2438edd3233",
      "ec899db2872a4d9d80e56e5319532900",
      "da44bef8495241b0838483ec0a2f7b74",
      "71e7748e686c4f7cb529e3b15191a48b",
      "385cab3cc94c4fb490742075882301cd",
      "7fcee88895944c7fb45897f9aa81ecba",
      "39f7373a77c24650ba28750e78424ea5",
      "aa143945314342df852112c54a78608c",
      "11a5c8b94c09465b8bc70b431d3bb419",
      "e51433bc423a43bf8000ac51c808dccf",
      "5d401b170afa4fbda592b2cf129cfa9a",
      "e8ae2e95ec86418dbf05cd7cc1f08a57",
      "5c6e03c08bff4f75b54510ce409ea3d1",
      "dcb8f41370004b6dab47148baead929a",
      "66b253c63dd243e9b6881814aa8640e6",
      "7c24c3ad104748009398db98bddac3b7",
      "6516524e9a9b426fbeb90b11e6bc7f4a",
      "0ee627d6252649d488702d1a36bd9360",
      "6c5c169cbad2401a97478b0e887dc1dc",
      "da60d1bbf323415a820f9871a1706c3d",
      "3a55fd1a44cb42dba191b2faf932e064"
     ]
    },
    "id": "kOiOM1DolJP9",
    "outputId": "f069f68e-e2f7-4171-f362-a52b5c7906d1"
   },
   "outputs": [],
   "source": [
    "# Change the tweets to tokens that the model can use\n",
    "dataset = dataset.map(tokenize_data, batched=True)\n",
    "\n",
    "# Transform\tlabels and remove the useless columns\n",
    "remove_columns = ['tweet_id', 'label', 'safe_text', 'agreement']\n",
    "dataset = dataset.map(transform_labels, remove_columns=remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1OMkK1elJP9",
    "outputId": "8f008b1b-280a-4406-ff51-acfb846d266c"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcQq_T3ofIoP"
   },
   "source": [
    "#### Balancing Target Classes\n",
    "\n",
    "Since our target has imbalanced class weights (positive, neutral and negative dont have an equal number of samples), we want to give more weight to underrepresented classes and give less weight to classes with more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCVvx_G8f4B5"
   },
   "outputs": [],
   "source": [
    "# Define the labels\n",
    "labels = dataset['train']['labels']\n",
    "\n",
    "# Apply the compute class weight function to calculate the class weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zk9kszhcgjHY"
   },
   "source": [
    "The `balanced` option in compute_class_weight will calculate weights such that the classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dD3rf-egNzq",
    "outputId": "972d8a41-3500-441e-c206-4d158ea2b566"
   },
   "outputs": [],
   "source": [
    "# Preview class weights\n",
    "class_weights, np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "aa1a3e97c8b748c29ea021d5bac7e66a",
      "d1d25a174a6a47838004cddfae4d9dfd",
      "a17fe5cdd7d84f75b4b7746fa48fe7ed",
      "90efdbcd70cc4100bff86979df36dcab",
      "91b4a84c86e94c77a36d1fe79683428f",
      "4151b72f3889454494e59fb471b3e823",
      "1dabeb9c904045c288ff8e827946c6c1",
      "64745f05f6e943f783f99fcca6899dfd",
      "21276b53ab7b491183aa895d270e3e29",
      "dd93d23d93744bfb98042dc451576a34",
      "ceb46264f84c4dff80261f14367bc88c"
     ]
    },
    "id": "sC4c_7DmgbTd",
    "outputId": "a962943a-53ed-4744-b2c6-8946f6d9e9ad"
   },
   "outputs": [],
   "source": [
    "# Define an instance of the pre-trained model with the number of labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcXBMgEXlJP-",
    "outputId": "5ab87570-d8fd-46aa-c979-85b05068e66e"
   },
   "outputs": [],
   "source": [
    "# Configure the training parameters\n",
    "\n",
    "training_args = TrainingArguments(\"./results\",\n",
    "    num_train_epochs=5, # the number of times the model will repeat the training loop over the dataset\n",
    "    load_best_model_at_end=True,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f64dd3dd20fc4f12a9e1a2d44594001d",
      "ab2b2ea14f9b48229158d22184bc9dfe",
      "05caf403f8bd485fba6c114dc5163473",
      "e2a71edea8314383a318921107c8d103",
      "da4c207b1b064298b31655d166c7446f",
      "49b8330343f84683aa1c346000f442c3",
      "0eb8b2c0e4f14edb80e4805e6b183bab",
      "9bcd83fb6fbc459584dc2581a4a02246",
      "3a252ebcabcb489388a394d70ec40ab2",
      "1e4873e5f7ad4ea19e61cd71ee2b2b8f",
      "d70e316f97744c4993dab49b5c947261"
     ]
    },
    "id": "f2leqie1FHgd",
    "outputId": "38a9720f-057f-445c-ea70-70a2d56581c5"
   },
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSrOQw7LlJP_"
   },
   "outputs": [],
   "source": [
    "# Instantiate the training and validation sets with random state of 10\n",
    "train_dataset = dataset['train'].shuffle(seed=10)\n",
    "eval_dataset = dataset['eval'].shuffle(seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xm3yEKLPaYtW"
   },
   "outputs": [],
   "source": [
    "# Convert train data to PyTorch tensors to speed up training and add padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,padding=True, max_length='max_length', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOk6hdz-k7L9"
   },
   "outputs": [],
   "source": [
    "# Define Custom Trainer | Modify loss function and assign computed weights\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Ensure logits and labels have compatible shapes and labels are of integer type\n",
    "        #assert logits.shape[1] == self.model.config.num_labels, f\"Logits shape {logits.shape} does not match number of labels {self.model.config.num_labels}\"\n",
    "        #assert labels.max() < self.model.config.num_labels, f\"Labels contain values outside the valid range: {labels}\"\n",
    "        #assert labels.dtype == torch.long, f\"Labels must be of type torch.long, but got {labels.dtype}\"\n",
    "\n",
    "        # Apply Class Weights\n",
    "        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(model.device)\n",
    "\n",
    "        # Compute custom loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzabvM_3mXAZ",
    "outputId": "8383be08-3a04-420a-bbb0-d7dd28d19a26"
   },
   "outputs": [],
   "source": [
    "# Instantiate the trainer for training\n",
    "c_trainer = CustomTrainer(\n",
    "                  model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=eval_dataset,\n",
    "                  tokenizer = tokenizer,\n",
    "                  compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "ymgbVXd4lJP_",
    "outputId": "60804fa7-9e4a-489a-e1a0-6287ddd5b2fd"
   },
   "outputs": [],
   "source": [
    "# Launch the learning process: training\n",
    "c_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s33CE3sdrA6T"
   },
   "source": [
    "`Training Loss`: The training loss is decreasing with each epoch, which is a positive sign. It suggests that the model is learning and improving its predictions on the training data.\n",
    "\n",
    "`Validation Loss`: The validation loss is relatively stable for the first 3 epochs but starts to increase thereafter. This could indicate overfitting, where the model is performing well on the training data but not generalizing as effectively on evaluation(unseen) data.\n",
    "\n",
    "`Accuracy`: The accuracy on the validation data is around 78% in the final epoch, which is a reasonable accuracy. The model is correctly predicting sentiments for approximately 78% of the validation samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "7sRbWJIjlJQA",
    "outputId": "bf3c474e-afb6-40e0-b89f-06db63282ee8"
   },
   "outputs": [],
   "source": [
    "# Launch the final evaluation\n",
    "c_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "7aa70413dafb499e944cbd9abbdc129a",
      "71159230e0ba4c5f8377ebab4cab24a5",
      "621a9d5bfd214d16b8de2cfaa69a4a92",
      "05305f9d62c74a5cb09881164e0de77c",
      "9a9692ffa3434d838d7961211190f26c",
      "1cc6d6effbce49038c412d7a3dc8c984",
      "b8594e19b5a9488fb8e3717c04acecb6",
      "7d46915a316e49a4af533e7f558a6045",
      "53808e4ce0d642d8a78f58f5d9527ea9",
      "8b89cdf38991435689c933acf87b0b1f",
      "919effdd48d744c9adacad69a474f1a5",
      "9e5d332cc14a493aae31322fae7e5c9f",
      "32de31e6cc594650bbde46b9e0e7977a",
      "12f933a88c7f4acf8246d0ea9a6eb2cf",
      "26798dffb4944cbabe83d2cc40b12115",
      "a244fc6359ed4219a827b4092ffac4c2",
      "7c425c177e774d1bbf083ffcf0b3eb50",
      "7493127c83c14b73808e96008b7dfda5",
      "3287d019124a4a12878118fe5f097d8a",
      "31b24bbef14c4fbfac2cf98c6f703fd6",
      "f63e347906274829913d2456edffa3f3",
      "3b87ec4732794ec798f14c3d64c454c9",
      "2b7b71c752c4466398c0d03da5538cb3",
      "4681cae51cbb4942b107960a19bf5cd1",
      "5795bd8ac12a43dba76145544cd2f460",
      "767214ce12f448c2a82e2663ecab8d01",
      "45f8423b47ae4e39b14f28281853ea5c",
      "ae1a094c3e2647999b9aed0359ff17f6",
      "e3d54afd12ca4051a06213258990bb8f",
      "e7e223779bc348fe9dc3dbd074d1fd2e",
      "a1ca6a1c513c462596a47d468ca9c69f",
      "37fb1d85c5614bb88514813d261f0b82",
      "274a4447873d4713afe1b5343229902a",
      "c556837d794144a4ab6cf32c64410982",
      "7fc6abdc82754644b0a82a9753bd662b",
      "c33c73e1152c45b098d7036020cca2d4",
      "5e6f61ed9f7a499a94c9dc187b1218a6",
      "568b12ed8a28411798764fbee8ffc2c6",
      "1e71d5eb72b94b3d896473357c5048ce",
      "7e185ee57d094e1d8971ce6f36276855",
      "f7acde0759b74e3d8bf5270b467f537c",
      "56879dfe354449b2ae69269b4baa8614",
      "191e895f85894a839da60c891271f87f",
      "c0b7f5b74fcd468d8183a51eaebc6688",
      "97dba185db4248628b28e9c32f2223a5",
      "8495fbb0072a4cc9b894426a762f18ed",
      "68955cd84a384685a595d1da87b8cfe5",
      "85b4e0cb616545c680c12294a987eb32",
      "b00036be32524fcab6cc3afbb612f800",
      "fa444144bb8d4a1cb37fd63211701e20",
      "9438e7a91e4a4940927c744a884ddd46",
      "9b23c92c3eb14b368f9f7645e9830fc3",
      "5cdd75de175840548d823c6902ab4baa",
      "bf564bcadb874c5ca8bd0028efa60d33",
      "96b3db0bcbb3403291fc8ff1bc77e7e8",
      "907900bb833142889c6f381233994332",
      "8b5f3094ecc34364b07893fb819f285e",
      "d013f12385ee445eb53d53489d2ed6a8",
      "0dbc5dffd749400c8938f1a1fe7cf9dc",
      "20b3eb182cb846d7bf8f9ab7ba5eb07e",
      "03814fba9b3349689eff039cdd0716fd",
      "3d462df67a474320bd9768386d2bf1fe",
      "74409d4da4e04e3592ad043dd5c5c6ce",
      "c07075209d894b619ab5f1ba5f00211b",
      "6bc759386d18401698c4c0378e191792",
      "42fdcaf70a5f49fa9d90e090f6eb0530"
     ]
    },
    "id": "fSTNCSkz0lhk",
    "outputId": "8a8b134f-ac16-45fd-b4db-9de80ce9b299"
   },
   "outputs": [],
   "source": [
    "# Push model and tokenizer to HF Hub\n",
    "model.push_to_hub(\"Azie88/COVID_Vaccine_Tweet_sentiment_analysis_roberta\")\n",
    "tokenizer.push_to_hub(\"Azie88/COVID_Vaccine_Tweet_sentiment_analysis_roberta\")\n",
    "dataset.push_to_hub(\"Azie88/COVID_Vaccine_Tweet_sentiment_analysis_roberta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkN2RIi5lJQB"
   },
   "source": [
    "This notebook is inspired by an article: [Fine-Tuning Bert for Tweets Classification ft. Hugging Face](https://medium.com/mlearning-ai/fine-tuning-bert-for-tweets-classification-ft-hugging-face-8afebadd5dbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSiIp6n33XnO"
   },
   "source": [
    "## Inference\n",
    "Let's test out our model with with some sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "0c1ca495c3eb4041a6015b2a581cdd47",
      "120f70466bea478ab77cfc44d68c0b61",
      "5938e690985347ff9e98544b86b1e284",
      "c467e2feddb2487abd2e90a9f1b0cd85",
      "832517a004d741ea9f528dc8bed22fe3",
      "ad57179ded224fde996ed96644ab0c1d",
      "97b76d02c0cc49269e99df08ac011f97",
      "91c1f73fc75d4840bd9a8b1377eb6bf6",
      "ef592e7cd07f40838668c847f393e6c7",
      "6229cbe42d4648149346a27121fab881",
      "59bc22eca64b46a8bac5569bba166b19",
      "f6122c52ff5b4b2c8aba9c0f9a87dd82",
      "b98a989cab124511931247f077e821b6",
      "07ed9eb82ffc42e6b2c45af811af2803",
      "026413447224438b97185192279941de",
      "adabd8c772574257b69d1be43344b630",
      "4e6e133e7b61417b9686d5d969c2cad8",
      "4482ed9857f749ad8cf81df457fdcbd0",
      "727879149e024b61b0a94de28e332c4a",
      "55cb141e396e475fb6011b20ff002859",
      "2f03b60e9405471e941e09dfa97f1247",
      "70b3d5eaa9904a358a0a23da20b94fb1",
      "0172d003e2f544b78d13a3752a8792a1",
      "7f58887079944ef2a43846c9fb009d04",
      "2ca737e1fd0b4e658881f586b12ceb50",
      "35ee385698e24dd59234fc9547d608d4",
      "08c8f716111a4785b76a1edc32d19875",
      "8018baac4c234d339392e9e896ebf5b7",
      "d1d7f141ebd84a20898edd9b64432ecb",
      "8a1d1c233d0049ffbf609cc18386f709",
      "870d708b6bd64072adae66258fcdfc7b",
      "ad7dacaf91684558a6a33418e15e27fb",
      "1deba58d5bf243cebc3fb0635a809192",
      "fdf7e0fa1cb848e781b13fedfc5fa288",
      "c438fe1df87f4132898d0c69a7aaa0bf",
      "41ea2a0860614905972fc74bfc681ad2",
      "bf3e68e145bd4332b2f71ed7d2698122",
      "05a3f8862ee24d62a33bdce723525e1c",
      "5f7fc4e38c4b43c293a56168adb36867",
      "0bd6e2a363c14d9d9cef81a701328884",
      "f33b84f6a1134c95aedae4c115a97b22",
      "803adf268a1348f1b9fad1a4ab51920e",
      "5025aa5b991d46aba17759eedce13f3e",
      "e513d32cf82849eab35c09f4c9af8f0e",
      "c7fa348b2a97402eb52df411bf43fce1",
      "f179abeef3554580958c703305c87d9d",
      "11d05066a0fd4fe78b232c74ab790800",
      "33b45c81439749148d345493c953a1f0",
      "dfcdbe986cf44843ba565831bc692182",
      "4d89c743aaed49858408aca90c32fee8",
      "499c1089606f416982dd7bf865a814f3",
      "436e6bfcd8ca4a67811bdfd32372a483",
      "af466dbd351e44638a99b794801b8baf",
      "8530e0237b4f48c3a22f26800eb97e45",
      "48e9de2ce2b2454a88d6da7011a6843d",
      "7536d1c223fa4399ae4cb730c8f6bde4",
      "6a093855875045019e3a33a960d46518",
      "a576b7c5f1b2479db28ed3afbca86bcd",
      "dccfcfa0495649c28434b30ce5df0473",
      "3e2d9cef84504a08bbd9a2b3c77f2ffc",
      "91b6fe52338143cdbfce09925ff30a08",
      "bf2e86c643bf480e866782ca9d3553b4",
      "e80ea6f0b6e046bda79b8c71b76d7f8b",
      "dd1f47c763d84d53b10bd273ebb06bc1",
      "8134ca64fffb47d2bf2ce4773564dfc2",
      "a2d039777bb5461484023d38613a761d",
      "553389d9518b4e948b1c3fad3190f177",
      "81883dad3e6b410a8162e7e777166c0c",
      "2ef2dbfe72704a92b4852f709f3d8171",
      "9a3ddcd0b53c410ea4203872d79d3d5b",
      "897869eeae2f435c899fc82f0b59d433",
      "dbf4e9678342456c8a10826cad47a5b6",
      "06255ba16be54c8eb4ef516b995e2f5f",
      "a83d8bb1c92a4c3ab763b850364258cf",
      "91d7c2869b794ac5845f6ae28bf5b391",
      "7472add542f34fe78fca6db44d7c910a",
      "ef1d20df379f498d84b608ca375b6520"
     ]
    },
    "id": "xMcAGcjstGya",
    "outputId": "6f31debc-e2ea-4e60-ffd9-ca8f9cf90300"
   },
   "outputs": [],
   "source": [
    "model_path = f\"Azie88/COVID_Vaccine_Tweet_sentiment_analysis_roberta\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anh244P_tkfg"
   },
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyXdDuM5tuak"
   },
   "outputs": [],
   "source": [
    "# Input preprocessing\n",
    "text = \"Covid vaccine is very effective\"\n",
    "text = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-1T8nRatyLC"
   },
   "outputs": [],
   "source": [
    "# PyTorch-based models\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKdPuis87Lg5",
    "outputId": "e34bee67-6ab7-4fdd-dba7-d078be5a4033"
   },
   "outputs": [],
   "source": [
    "print(\"Scores:\", scores)\n",
    "print(\"id2label Dictionary:\", config.id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jfpd8LBrt3Uf"
   },
   "outputs": [],
   "source": [
    "config.id2label = {0: 'NEGATIVE', 1: 'NEUTRAL', 2: 'POSITIVE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caXxBYeZt6Qs",
    "outputId": "7a65379b-9578-4cd0-8310-e751df63001d"
   },
   "outputs": [],
   "source": [
    "# Print labels and scores\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ab24538aa0da4b2d8c48eaca591ff7ffc54671225fb0511b432fd9e26a098ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
